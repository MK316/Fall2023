{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNT+C2i/+Nv09R4YjBm3EcT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MK316/Fall2023/blob/main/18Sentences_inspection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸŒ€ Audio file to play\n",
        "\n",
        "1. Installation\n",
        "2. Upload your speech file (by sentences) A total of 18 sentences\n",
        "3. Run comarison"
      ],
      "metadata": {
        "id": "HJuXfaZbCBak"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [1] Installation"
      ],
      "metadata": {
        "id": "66frGN9JQ-eL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hPKdMUJvB9rz"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install librosa matplotlib nltk SpeechRecognition ipywidgets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# [2] File to upload"
      ],
      "metadata": {
        "id": "iya1OHbhQO3K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## [3] Original sentence texts & Recognized\n",
        "- Comparison: Similarity score: 0~1"
      ],
      "metadata": {
        "id": "XBjCMZIyKjgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "filename = input('Write the full file name: (e.g., sample.wav)')"
      ],
      "metadata": {
        "id": "jH6ZUqXmCYSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"2\" #@param = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18]\n",
        "sn = int(sentence)\n",
        "\n",
        "# filename = input(\"File name: (e.g., sample.wav)\")\n",
        "\n",
        "sents = [ \"Please believe that sweet peas and beans are good to eat. Eat them at least twice a week.\",\n",
        "\"Tim's sister swims a little bit. It keeps her fit slim and trim.\",\n",
        "\"Ten times seven is seventy. Seven times eleven is seventy-seven.\",\n",
        "\"Many animals inhabit Africa. Africa has camels giraffes parrots and bats.\",\n",
        "\"Doctors say jogging is good for the body. Lots of starch causes heart problems.\",\n",
        "\"Who flew to the moon? Numerous lunar flights are in the news. We'll soon put a person on Jupiter and Pluto.\",\n",
        "\"Would you look for my cookbook? It should be full of hints for good cookies and pudding.\",\n",
        "\"The southern governor is Republican. The public election was fun. She won by one hundred votes.\",\n",
        "\"The author gave a long talk in the office. The small audience thought it was boring.\",\n",
        "\"Nurses do worthy work. They certainly deserve a word of praise.\",\n",
        "\"Labor Day is in September. Workers are honored.\",\n",
        "\"Maine is a state in the northern United States. It's a great place for a vacation.\",\n",
        "\"The North Pole is close to the Arctic Ocean. It's known for polar bears snow and severe cold.\",\n",
        "\"Owls are now found throughout the world. They avoid crowds and make loud sounds.\",\n",
        "\"Eyesight is vital for a normal life. I prize mine highly.\",\n",
        "\"The auto industry is a loyal employer in Detroit. People enjoy their choice of cars.\",\n",
        "\"Africa Asia Australia South America and Europe comprise five of the continents. North America is another continent.\",\n",
        "\"I have televisions in the bedroom living room and dining room. The programs about detectives and hospitals are my favorites.\"\n",
        "]\n",
        "\n",
        "mytext = sents[sn-1]\n",
        "# print(\"The original text: %s\"%mytext)\n",
        "\n",
        "# !pip install librosa matplotlib SpeechRecognition\n",
        "\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import speech_recognition as sr\n",
        "import numpy as np\n",
        "\n",
        "recognized_text = \"\"\n",
        "def transcribe_audio(file_path):\n",
        "    recognizer = sr.Recognizer()\n",
        "    with sr.AudioFile(file_path) as source:\n",
        "        audio_data = recognizer.record(source)\n",
        "        try:\n",
        "            text = recognizer.recognize_google(audio_data)\n",
        "            recognized_text = text\n",
        "            return text\n",
        "        except sr.UnknownValueError:\n",
        "            return \"Could not understand audio\"\n",
        "        except sr.RequestError as e:\n",
        "            return f\"Error: {e}\"\n",
        "\n",
        "def plot_waveform_with_transcription(file_path, transcription):\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    librosa.display.waveshow(audio, sr=sr)\n",
        "    plt.title('Waveform with Transcription')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.figtext(0.5, 0.02, f\"Transcription: {transcription}\", wrap=True, horizontalalignment='center', fontsize=12)\n",
        "    plt.show()\n",
        "\n",
        "import difflib\n",
        "\n",
        "\n",
        "\n",
        "# Function to compare two texts\n",
        "def compare_texts(user_text, recognized_text):\n",
        "    # Use SequenceMatcher to calculate similarity\n",
        "    similarity = difflib.SequenceMatcher(None, user_text, recognized_text).ratio()\n",
        "\n",
        "    print(f\"Similarity Score: {similarity:.2f}\")\n",
        "    print(\"\\nUser-Provided Text:\\n\", user_text)\n",
        "    print(\"\\nRecognized Text:\\n\", recognized_text)\n",
        "\n",
        "    # If detailed comparison is needed, you can add more analysis here\n",
        "\n",
        "\n",
        "\n",
        "# Example Usage\n",
        "file_path = '/content/' + filename  # Replace with your audio file path\n",
        "transcription = transcribe_audio(file_path)\n",
        "\n",
        "# Example usage\n",
        "user_text = mytext  # Replace with the text provided by the user\n",
        "recognized_text = transcription  # Replace with the text from speech recognition\n",
        "compare_texts(user_text, recognized_text)\n",
        "\n",
        "\n",
        "plot_waveform_with_transcription(file_path, transcription)\n",
        "\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "7H8Kle1SMbLW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zoom-in for inspection\n",
        "+ waveform\n",
        "+ audio"
      ],
      "metadata": {
        "id": "TTnDMwbtRIPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown Generate the audio part\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import Audio, display, clear_output\n",
        "import ipywidgets as widgets\n",
        "import numpy as np\n",
        "\n",
        "# Function to display a section of the waveform and play audio for that section\n",
        "def display_waveform_and_play_audio(file_path, start_time, end_time):\n",
        "    audio, sr = librosa.load(file_path, sr=None)\n",
        "\n",
        "    start_sample = int(start_time * sr)\n",
        "    end_sample = int(end_time * sr)\n",
        "    selected_audio = audio[start_sample:end_sample]\n",
        "\n",
        "    plt.figure(figsize=(10, 4))\n",
        "    librosa.display.waveshow(selected_audio, sr=sr, alpha=0.5)\n",
        "    plt.title(f'Waveform (from {start_time}s to {end_time}s)')\n",
        "    plt.xlabel('Time (s)')\n",
        "    plt.ylabel('Amplitude')\n",
        "    plt.show()\n",
        "\n",
        "    display(Audio(data=selected_audio, rate=sr))\n",
        "\n",
        "# Interactive widgets\n",
        "start_time_input = widgets.FloatText(value=0.0, description='Start Time (s):')\n",
        "end_time_input = widgets.FloatText(value=0.0, description='End Time (s):')\n",
        "audio_button = widgets.Button(description='Play Audio')\n",
        "output_area = widgets.Output()\n",
        "\n",
        "file_path = '/content/' + filename  # Replace with your file path\n",
        "\n",
        "def on_audio_button_clicked(b):\n",
        "    with output_area:\n",
        "        clear_output(wait=True)\n",
        "        display_waveform_and_play_audio(file_path, start_time_input.value, end_time_input.value)\n",
        "\n",
        "audio_button.on_click(on_audio_button_clicked)\n",
        "\n",
        "# Display widgets\n",
        "display(widgets.VBox([start_time_input, end_time_input, audio_button]))\n",
        "display(output_area)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "zctfJmrbPof7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}